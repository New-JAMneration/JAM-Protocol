package auditing

import (
	"crypto/ed25519"
	"fmt"

	"github.com/New-JAMneration/JAM-Protocol/internal/header"
	"github.com/New-JAMneration/JAM-Protocol/internal/safrole"
	"github.com/New-JAMneration/JAM-Protocol/internal/store"
	"github.com/New-JAMneration/JAM-Protocol/internal/types"
	"github.com/New-JAMneration/JAM-Protocol/internal/utilities"
	"github.com/New-JAMneration/JAM-Protocol/internal/utilities/hash"
	"github.com/New-JAMneration/JAM-Protocol/internal/utilities/shuffle"
)

// (17.1) Q âˆˆ âŸ¦W?âŸ§C(17.1)
// (17.2) Q â‰¡ Ï[c]w if Ï[c]w âˆˆ W
//
//	âˆ… otherwise 		c <âˆ’ NC
//
// GetQ constructs the audit report candidates Q (formula 17.1 ~ 17.2).
func GetQ() []*types.WorkReport {
	store := store.GetInstance()

	// Ï(rho): Current assignment map (per core)
	rho := store.GetPriorStates().GetRho()

	// W: Available work reports
	W := store.GetAvailableWorkReportsPointer().GetAvailableWorkReports()

	// Create a set of available work package hashes
	available := make(map[types.WorkPackageHash]bool)
	for _, report := range W {
		available[report.PackageSpec.Hash] = true
	}

	Q := make([]*types.WorkReport, types.CoresCount)
	for index, assignment := range rho {
		// check if core has an assignment
		if assignment != nil {
			report := assignment.Report
			// Only keep it if the assigned report is still available in W (Ï[c]w âˆˆ W)
			if available[report.PackageSpec.Hash] {
				Q[index] = &report
			}
			// else: Q[index] stays nil (âˆ… otherwise c <âˆ’ NC)
		}
	}
	return Q
}

// GetS0 computes the initial audit seed sâ‚€ for a validator, following Formula (17.3)-(17.4).
// Returns the VRF output (sâ‚€) as BandersnatchVrfSignature.
func GetS0(validatorIndex int) (types.BandersnatchVrfSignature, error) {
	store := store.GetInstance()
	priorStates := store.GetPriorStates()

	entropyHash, err := GetYHv() // Y(Háµ¥): VRF output of block author's entropy
	if err != nil {
		return types.BandersnatchVrfSignature{}, fmt.Errorf("failed to get Y(Háµ¥): %w", err)
	}

	// Construct context XU âŒ¢ Y(Háµ¥)
	context := append(types.ByteSequence(types.JamAudit[:]), entropyHash...)

	// Sign the context with validator's key and extract VRF output
	validatorKey := priorStates.GetKappa()[validatorIndex].Bandersnatch
	validatorVRF, err := safrole.CreateVRFHandler(validatorKey)
	if err != nil {
		return types.BandersnatchVrfSignature{}, fmt.Errorf("failed to create validator VRF handler: %w", err)
	}

	// Sign the context (empty message)
	vrfSignature, err := validatorVRF.IETFSign(context, []byte(""))
	if err != nil {
		return types.BandersnatchVrfSignature{}, fmt.Errorf("failed to sign audit context: %w", err)
	}

	// Derive VRF output from signature
	s0, err := validatorVRF.VRFIetfOutput(vrfSignature[:])
	if err != nil {
		return types.BandersnatchVrfSignature{}, fmt.Errorf("failed to compute VRF output: %w", err)
	}

	return types.BandersnatchVrfSignature(s0), nil
}

// ComputeA0ForValidator generates the initial audit assignment a0 for a given validator,
// based on formulas (17.3)~(17.7):
//
//	(17.3) s0 = VRFâŸ¨XU âŒ¢ Y(Háµ¥)âŸ© using validator key
//	(17.7) r = ğ’´(s0)    â†’ VRF output over sâ‚€
//	(17.6) p = Shuffle([0..CoresCount), r)
//	(17.5) a0 = top 10 of (c, Q[c]) where Q[c] â‰  âˆ…
//
// Returns a list of AuditReports
func ComputeA0ForValidator(Q []*types.WorkReport, validatorIndex int) ([]types.AuditReport, error) {
	store := store.GetInstance()

	// Get initial audit seed s0 (17.3)
	s0, err := GetS0(validatorIndex)
	if err != nil {
		return nil, fmt.Errorf("ComputeA0ForValidator: failed to get s0: %w", err)
	}

	// Compute r = ğ’´(s0) â€” derive audit random seed (17.7)
	validatorKey := store.GetPosteriorStates().GetKappa()[validatorIndex].Bandersnatch
	handler, err := safrole.CreateVRFHandler(validatorKey)
	if err != nil {
		return nil, fmt.Errorf("ComputeA0ForValidator: failed to create VRF handler for validator: %w", err)
	}

	vrfOutput, err := handler.VRFIetfOutput(s0[:])
	if err != nil {
		return nil, fmt.Errorf("ComputeA0ForValidator: failed to get VRF output from sâ‚€: %w", err)
	}

	// Generate core shuffle p = F([0..N], r) (17.6)
	coreIndices := make([]types.U32, types.CoresCount)
	for i := range coreIndices {
		coreIndices[i] = types.U32(i)
	}
	shuffled := shuffle.Shuffle(coreIndices, types.OpaqueHash(vrfOutput))

	// Step 4: Select top 10 assigned reports (17.5)
	var a0 []types.AuditReport
	for _, coreIdx := range shuffled {
		report := Q[coreIdx]
		if report != nil {
			a0 = append(a0, types.AuditReport{
				CoreID:      types.CoreIndex(coreIdx),
				Report:      *report,
				AuditResult: false,
			})
			if len(a0) == 10 {
				break
			}
		}
	}

	return a0, nil
}

// (17.8) let n = (T âˆ’ P â‹… Ht) / A
// GetTranchIndex computes tranche index from wall-clock time and block slot
func GetTranchIndex() types.U64 {
	T := types.U64(header.GetCurrentTimeInSecond())                   // T current time (seconds)
	Ht := types.U64(store.GetInstance().GetIntermediateHeader().Slot) // Ht slot number from block header
	P := types.U64(types.SlotPeriod)                                  // P: seconds per slot
	A := types.U64(types.TranchePeriod)                               // A: seconds per tranche
	n := (T - P*Ht) / A                                               // n = (T - P â‹… Ht) / A
	return n
}

// BuildAnnouncement generates the announcement signature S
// over the validator's audit assignment aâ‚™ at tranche index n,
// following formula:
// S â‰¡ EÎº[v]e âŸ¨XI + n âŒ¢ xn âŒ¢ H(H)âŸ©
func BuildAnnouncement(
	n types.U8, // tranche index
	an []types.AuditReport, // an: assignment at tranche n
	hashFunc func(types.ByteSequence) types.OpaqueHash, // H(w): hash function
	validatorIndex int,
	validatorPrivKey ed25519.PrivateKey, // Îº[v]áµ‰: Ed25519 private key
) types.Ed25519Signature {

	// (17.10) Compute xn = concat of E([E2(c) âŒ¢ H(w)] for all (c, w) âˆˆ an)
	var xnPayload types.ByteSequence
	for _, pair := range an {
		coreID := utilities.SerializeFixedLength(types.U64(pair.CoreID), 2) // E2(c)
		hashW := hashFunc(utilities.WorkReportSerialization(pair.Report))   // H(w)
		xnPayload = append(xnPayload, coreID...)
		xnPayload = append(xnPayload, hashW[:]...)
	}
	xn := utilities.SerializeByteSequence(xnPayload)

	// (17.11) XI = $jam_announce
	XI := types.ByteSequence(types.JamAnnounce[:])

	// Get H(H): hash of the intermediate header
	header := store.GetInstance().GetIntermediateHeader()
	headerHash := hashFunc(utilities.HeaderSerialization(header))

	// (17.9) context = âŸ¨XI âŒ¢ n âŒ¢ xn âŒ¢ H(H)âŸ©
	context := XI
	context = append(context, utilities.SerializeFixedLength(types.U32(n), 4)...) // âŒ¢ n
	context = append(context, xn...)                                              // âŒ¢ xn
	context = append(context, headerHash[:]...)                                   // âŒ¢ H(H)

	// Sign context with validator Ed25519 private key: S = Sign(context)
	signature := ed25519.Sign(validatorPrivKey, context)
	return types.Ed25519Signature(signature)
}

// (17.12) GetAssignedValidators returns the set Aâ‚™(w) of validators assigned to work-report w.
func GetAssignedValidators(
	w types.WorkReport,
	An types.AssignmentMap, // An: assignment map
) []types.ValidatorIndex {
	if assigned, ok := An[w.PackageSpec.Hash]; ok {
		return assigned
	}
	return []types.ValidatorIndex{} // âˆ… if not found
}

// (17.13) âˆ€(c, w) âˆˆ a0 âˆ¶ v âˆˆ q0(w)
func UpdateAssignmentMap(
	A0 []types.AuditReport,
	An types.AssignmentMap, // An: assignment map
) types.AssignmentMap {
	for _, audit := range A0 {
		hash := audit.Report.PackageSpec.Hash
		if _, ok := An[hash]; !ok {
			An[hash] = []types.ValidatorIndex{}
		}
		An[hash] = append(An[hash], audit.ValidatorID)
	}
	return An
}

// ClassifyJudgments categorizes the validators who gave positive (JâŠ¤) or negative (JâŠ¥) judgments for a given work report.
// It uses the work report's hash to determine matching judgments.
func ClassifyJudgments(
	report types.WorkReport,
	judgments []types.AuditReport, // All validators' audit judgments
) (positives map[types.ValidatorIndex]bool, negatives map[types.ValidatorIndex]bool) {
	positives = make(map[types.ValidatorIndex]bool)
	negatives = make(map[types.ValidatorIndex]bool)
	reportHash := report.PackageSpec.Hash

	for _, j := range judgments {
		if j.Report.PackageSpec.Hash == reportHash {
			if j.AuditResult {
				positives[j.ValidatorID] = true // JâŠ¤: Positive judgments
			} else {
				negatives[j.ValidatorID] = true // JâŠ¥: Negative judgments
			}
		}
	}
	return
}
func GetYHv() ([]byte, error) {
	// Compute Y(Háµ¥) â€” entropy hashed by block author's key
	store := store.GetInstance()
	priorStates := store.GetPriorStates()
	header := store.GetIntermediateHeader()
	authorKey := priorStates.GetKappa()[header.AuthorIndex].Bandersnatch
	authorVRF, err := safrole.CreateVRFHandler(authorKey)
	if err != nil {
		return []byte{}, fmt.Errorf("failed to create author VRF handler: %w", err)
	}

	entropyHash, err := authorVRF.VRFIetfOutput(header.EntropySource[:])
	if err != nil {
		return []byte{}, fmt.Errorf("failed to compute Y(Háµ¥): %w", err)
	}
	return entropyHash, nil
}

// (17.15) sn(w) âˆˆ F[] Îº[v]b âŸ¨XU âŒ¢ Y(Hv) âŒ¢ H(w) nâŸ©
// (17.16) an â‰¡ { V/256F Y(sn(w))0 < mn | w âˆˆ Q, w â‰  âˆ…}
// where mn = SAnâˆ’1(w) âˆ– JâŠº(w)S
func ComputeAnForValidator(
	n types.U8,
	Q []*types.WorkReport,
	priorAssignments map[types.WorkPackageHash][]types.ValidatorIndex, // Aâ‚™â‚‹â‚(w)
	positiveJudgers map[types.WorkPackageHash]map[types.ValidatorIndex]bool, // JâŠ¤(w)
	hashFunc func(types.ByteSequence) types.OpaqueHash,
	v int,
) ([]types.AuditReport, error) {
	var an []types.AuditReport

	store := store.GetInstance()
	priorStates := store.GetPriorStates()

	// Y(Háµ¥): VRF output of block author's entropy
	Y_Hv, err := GetYHv()
	if err != nil {
		return nil, fmt.Errorf("failed to get Y(Háµ¥): %w", err)
	}

	// validator handler
	validatorKey := priorStates.GetKappa()[v].Bandersnatch
	vrfHandler, err := safrole.CreateVRFHandler(validatorKey)
	if err != nil {
		return nil, fmt.Errorf("CreateVRFHandler for validator: %w", err)
	}

	for _, wPtr := range Q {
		if wPtr == nil {
			continue
		}
		report := *wPtr
		reportHash := report.PackageSpec.Hash
		assignedValidators := priorAssignments[reportHash]
		positiveJudgedMap := positiveJudgers[reportHash]

		// mâ‚™ = |Aâ‚™â‚‹â‚(w) âˆ– JâŠ¤(w)|
		noShowCount := 0
		for _, vid := range assignedValidators {
			if !positiveJudgedMap[vid] {
				noShowCount++
			}
		}
		if noShowCount == 0 {
			continue
		}

		// Build context âŸ¨XU âŒ¢ Y(Hv) âŒ¢ H(w) âŒ¢ nâŸ©
		conext := types.ByteSequence(types.JamAudit[:])                               // XU
		context := append(conext, Y_Hv...)                                            // Y(Hv)
		Hw := hashFunc(utilities.WorkReportSerialization(report))                     // H(w)
		context = append(context, Hw[:]...)                                           // H(w)
		context = append(context, utilities.SerializeFixedLength(types.U32(n), 4)...) // n

		// Compute sâ‚™(w)
		signature, err := vrfHandler.IETFSign(context, []byte(""))
		if err != nil {
			return nil, fmt.Errorf("signing sâ‚™(w) failed: %w", err)
		}
		sn_w, err := vrfHandler.VRFIetfOutput(signature[:])
		if err != nil {
			return nil, fmt.Errorf("VRF output Y(sâ‚™(w)) failed: %w", err)
		}

		//  V * Y(sn(w))0 / 256F < m
		// This report is assigned to the validator
		if int(sn_w[0])*types.ValidatorsCount/(256*types.BiasFactor) < noShowCount {
			an = append(an, types.AuditReport{
				CoreID:      report.CoreIndex,
				Report:      report,
				ValidatorID: types.ValidatorIndex(v),
				AuditResult: false,
			})
		}
	}

	return an, nil
}

/*
// e_n(w): 17.17 ç”¢ç”Ÿ audit çµæœ
func EvaluateReport(
	report types.WorkReport,
	coreID types.CoreIndex,
	proposals []types.WorkPackageProposal, // proposal from peers
	decodeFunc func(types.WorkPackageProposal, types.CoreIndex) (types.WorkReport, bool),
	encodeFunc func(types.WorkReport) types.WorkPackageEncoding,
) *types.WorkReport {
	targetEncoding := encodeFunc(report)

	for _, p := range proposals {
		// check if the decoded report matches the given one
		if decoded, ok := decodeFunc(p, coreID); ok {
			if encodeFunc(decoded) == targetEncoding {
				return &decoded // match found: return the decoded report
			}
		}
	}
	return nil // âŠ¥ â€” evaluation failed
}*/

// (17.18) n = {SÎº[v]e (Xe(w) âŒ¢ H(w)) S (c, w) âˆˆ an}
func BuildJudgements(
	tranche types.U8,
	auditReports []types.AuditReport, // (c, w) âˆˆ aâ‚™
	hashFunc func(types.ByteSequence) types.OpaqueHash,
	validator_index int,
) []types.AuditReport {
	for index, audit := range auditReports {
		report := audit.Report
		// Xe
		var context types.ByteSequence
		if audit.AuditResult {
			context = []byte("$jam_valid")
		} else {
			context = []byte("$jam_invalid")
		}

		// Hash the report content
		hashW := hashFunc(utilities.WorkReportSerialization(report)) // H(w)
		context = append(context, hashW[:]...)                       // Xe(w) âŒ¢ H(w)

		// Sign the message
		validator_key := store.GetInstance().GetPosteriorStates().GetKappa()[validator_index].Ed25519
		signature := ed25519.Sign(validator_key[:], context)
		auditReports[index].Signature = types.Ed25519Signature(signature)
	}

	return auditReports
}

// (17.19) Determines if a single work report is considered audited.
func IsWorkReportAudited(
	report types.WorkReport,
	judgments []types.AuditReport,
	assignedValidators []types.ValidatorIndex, // Aâ‚™(w)
) bool {
	positiveJudges, negativeJudges := ClassifyJudgments(report, judgments)

	// Rule 1: No negatives AND all assigned validators gave a positive judgment
	if len(negativeJudges) == 0 {
		allAssignedConfirmed := true
		for _, validator := range assignedValidators {
			if !positiveJudges[validator] {
				allAssignedConfirmed = false
				break
			}
		}
		if allAssignedConfirmed {
			return true
		}
	}

	// Rule 2: Supermajority of positive judgments
	if len(positiveJudges) >= types.ValidatorsSuperMajority {
		return true
	}

	return false
}

// Filters audit judgments that match the target report hash.
func FilterJudgments(judgments []types.AuditReport, targetHash types.WorkPackageHash) []types.AuditReport {
	var filtered []types.AuditReport
	for _, j := range judgments {
		if j.Report.PackageSpec.Hash == targetHash {
			filtered = append(filtered, j)
		}
	}
	return filtered
}

// (17.20) Checks if ALL work reports are fully audited.
func IsBlockAudited(
	workReports []types.WorkReport,
	allJudgments []types.AuditReport,
	assignmentMap map[types.WorkPackageHash][]types.ValidatorIndex,
) bool {
	for _, report := range workReports {
		hash := report.PackageSpec.Hash
		assignedValidators := GetAssignedValidators(report, assignmentMap)
		filteredJudgments := FilterJudgments(allJudgments, hash)

		if !IsWorkReportAudited(report, filteredJudgments, assignedValidators) {
			return false // One report not audited: block incomplete
		}
	}
	return true
}

func PublishAuditReport(audit types.AuditReport) error {
	// TODO: Implement the logic to publish the audit report
	// This could involve sending the report to a network, saving it to a database, etc.
	return nil
}

func SingleNodeAuditingAndPublish(validatorIndex int, validatorPrivKey ed25519.PrivateKey) error {
	// Step 1: Collect work reports assigned per core (17.1â€“17.2)
	Q := GetQ()
	reports_for_block := []types.WorkReport{}
	for _, report := range Q {
		if report != nil {
			reports_for_block = append(reports_for_block, *report)
		}
	}

	// Step 2: Prepare assignment map Aâ‚™â‚‹â‚(w) and judgement state JâŠ¤(w)
	assignmentMap := make(map[types.WorkPackageHash][]types.ValidatorIndex)
	positiveJudgers := make(map[types.WorkPackageHash]map[types.ValidatorIndex]bool)

	// Step 3: Compute initial deterministic assignment aâ‚€ (17.3â€“17.7)
	a0, err := ComputeA0ForValidator(Q, validatorIndex)
	if err != nil {
		return fmt.Errorf("failed to compute aâ‚€: %w", err)
	}

	// Step 4: Store aâ‚€ into assignment map (only own info known at this point)
	for _, item := range a0 {
		hash := item.Report.PackageSpec.Hash
		assignmentMap[hash] = append(assignmentMap[hash], types.ValidatorIndex(validatorIndex))
	}

	// Step 5: Publish CE144 Announcement for aâ‚€
	announcement := BuildAnnouncement(0, a0, hash.Blake2bHash, validatorIndex, validatorPrivKey)
	fmt.Println("Announcement:", announcement)
	/* TODO broadcast announcement CE144
	if err := BroadcastAnnouncement(announcement); err != nil {
		return fmt.Errorf("failed to broadcast aâ‚€ announcement: %w", err)
	}*/

	// TODOã€€Evaluate initial judgments (17.17)
	for i := range a0 {
		// TODO audit function a0[i].AuditResult = EvaluateAuditReport(a0[i].Report) // Placeholder
		if a0[i].AuditResult {
			hash := a0[i].Report.PackageSpec.Hash
			if _, ok := positiveJudgers[hash]; !ok {
				positiveJudgers[hash] = make(map[types.ValidatorIndex]bool)
			}
			positiveJudgers[hash][types.ValidatorIndex(validatorIndex)] = true
		}
	}

	// Sign and broadcast CE145 judgments
	signedA0 := BuildJudgements(0, a0, hash.Blake2bHash, validatorIndex)
	for _, audit := range signedA0 {
		err := PublishAuditReport(audit)
		if err != nil {
			return fmt.Errorf("failed to publish audit report for core %d: %w", audit.CoreID, err)
		}
	}

	// TODO: Wait for CE144/145 messages from peers
	//       Update assignmentMap and positiveJudgers
	/*
		receivedAnnouncements := WaitForAnnouncements()
		UpdateAssignmentMapAndPositiveJudgers(receivedAnnouncements, assignmentMap, positiveJudgers)
	*/

	// Step 9: Iterate over tranches (stochastic audit)
	// 7. é–‹å§‹ audit process loop for tranche n â‰¥ 1
	for tranche := types.U8(1); ; tranche++ {
		// (17.15) è¨ˆç®—è£œå¯© assignment an
		an, err := ComputeAnForValidator(tranche, Q, assignmentMap, positiveJudgers, hash.Blake2bHash, validatorIndex)
		if err != nil {
			return fmt.Errorf("failed to compute aâ‚™: %w", err)
		}

		// (17.17) å¯©æŸ¥å ±å‘Šå…§å®¹ï¼šæ±ºå®šæ˜¯å¦æ­£å¯©
		/* TODO EvaluateReport
		for i := range an {
			// an[i].AuditResult = EvaluateReport(an[i].Report) // TODO: æ ¹æ“šå¯¦éš›åˆ¤æ–·æ¢ä»¶å¯¦ä½œ
		}*/

		// (17.18) Sign
		signed := BuildJudgements(tranche, an, hash.Blake2bHash, validatorIndex)

		// Update positiveJudgers
		for _, audit := range signed {
			if audit.AuditResult {
				h := audit.Report.PackageSpec.Hash
				if _, ok := positiveJudgers[h]; !ok {
					positiveJudgers[h] = make(map[types.ValidatorIndex]bool)
				}
				positiveJudgers[h][audit.ValidatorID] = true
			}
		}

		// broadcast CE145
		for _, audit := range signed {
			if err := PublishAuditReport(audit); err != nil {
				return fmt.Errorf("failed to publish audit report for core %d: %w", audit.CoreID, err)
			}
		}

		// broadcast (optional CE144 tranche n)
		// TODO: Build and broadcast tranche n announcement
		/*
			announcement := BuildAnnouncement(tranche, an, ...)
			err := BroadcastAnnouncement(announcement)
		*/

		// TODO: Wait CE144 / CE145 update assignmentMap å’Œ positiveJudgers

		// æª¢æŸ¥æ˜¯å¦æ‰€æœ‰å ±å‘Šéƒ½å®Œæˆå¯©æŸ¥ (17.20)
		if IsBlockAudited(reports_for_block, signed, assignmentMap) {
			break
		}
	}
	return nil
}
